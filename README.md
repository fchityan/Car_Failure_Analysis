ğŸ“Œ Project Overview

This project analyzes a vehicle operational dataset to explore factors associated with car failures.

The notebook is designed to be:

	â€¢ Exploratory Data Analysis (EDA)
	â€¢ Data Cleaning and Preprocessing
	â€¢ Feature Transformation and Encoding
	â€¢ Handling Class Imbalance
	â€¢ Training and Evaluating a Classification Model

The primary goal is to understand the dataset's structure and investigate how preprocessing decisions influence classification performance. 

ğŸ¯ Objective

The objective of this project is to develop a classification model capable of predicting vehicle failure events based on operational features:

Specifically, the analysis aims to:

	â€¢ Identify patterns in vehicle operational metrics
	â€¢ Address data quality issues
	â€¢ Design appripriate encoding strategies for categorical features
	â€¢ Handle significant class imbalance
	â€¢ Evaluate model performance using relevant classification metrics

 ğŸ“Š Dataset Overview

Key characteristics identified during EDA:

	â€¢	âš ï¸ Negative values present in RPM
	â€¢	ğŸ“ˆ Fuel consumption is slightly right-skewed
	â€¢	ğŸŒ¡ï¸ Temperature forms two clearly separable clusters
	â€¢	ğŸš— High cardinality in car model, making one-hot encoding impractical
	â€¢	ğŸŒ³ Categorical feature distributions vary widely, favoring tree-based models
	â€¢	ğŸ”§ Each car can experience only one failure type
	â€¢	âš–ï¸ Strong target imbalance (>80% non-failure cases)


ğŸ” Exploratory Data Analysis (EDA)

The exploratory phase focused on:

Numerical Features:

	â€¢ Distribution analysis
	â€¢ Detection of invalid values
	â€¢ Identification of skewness and clustering

Categorical Features:

	â€¢ Cardinality assessment
	â€¢ Category distribution analysis
	â€¢ Encoding suitability evaluation

Target Distribution:

The dataset presents a highly imbalanced classificatin problem:

	â€¢ Majority: Non-failure
	â€¢ Minority: Failure

This imbalance significantly influences model evaluation and interpretation.

 ğŸ“¦ Initial Dataset Size
 
	â€¢	10,081 rows
	â€¢	14 columns

 ğŸŒ¡ï¸ Temperature Encoding Rationale

The distribution of temperature values showed a clean separation into two low-variance clusters. Encoding these as High and Low reduces noise while preserving signal.

After cleaning:

	â€¢	9,857 rows
	â€¢	13 columns

 ğŸ·ï¸ Feature Encoding

After cleaning:

	â€¢	Numerical features: RPM, Fuel Consumption
	â€¢	All other features are categorical

Encoding Strategy
	â€¢	ğŸ”¢ Mean weight encoding for high-cardinality features
	â€¢	ğŸ”  One-hot encoding for low-cardinality features
	â€¢	ğŸ”§ Failure columns merged into a single Faults column

After encoding:

	â€¢	9,857 rows
	â€¢	23 columns

ğŸ“‰ Dataset Size After Preparation

Before Train/Test Split:

	â€¢	Balanced dataset: 1,496 rows
	â€¢	Unbalanced dataset: 9,857 rows

 âœ… Key Takeaways
 
	â€¢	Data cleaning significantly improves model reliability
	â€¢	Encoding strategy affects dimensionality and predictive performance
	â€¢	Class imbalance has a strong impact on evaluation metrics
	â€¢	Balancing improves minority class detection but may reduce overall accuracy
